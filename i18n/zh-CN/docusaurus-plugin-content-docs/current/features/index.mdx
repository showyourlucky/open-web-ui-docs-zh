---
sidebar_position: 400
title: "⭐ 功能特点"
---
import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Open WebUI 的主要功能 ⭐

- 🚀 **简便设置**: 使用 Docker 或 Kubernetes (`kubectl`, `kustomize` 或 `helm`) 轻松安装，无缝体验，支持包含 Ollama 的 `:ollama` 镜像和支持 CUDA 的 `:cuda`。

- 🤝 **OpenAI API 集成**: 轻松集成兼容 OpenAI 的 API，实现与 Ollama 模型的多样化对话。OpenAI API URL 可定制化，以链接到各种第三方应用。

- 🛡️ **细粒度权限和用户组**: 允许管理员创建详细的用户角色和权限，以确保安全的用户环境。这种细致性不仅增强了安全性，还允许定制用户体验，培养用户的归属感和责任感。

- 📱 **响应式设计**: 在台式机、笔记本电脑和移动设备上享受无缝体验。

- 📱 **移动端渐进式 Web 应用**: 在移动设备上享受本地渐进式 Web 应用体验，可在 `localhost` 或个人域名上离线访问，界面流畅。为了使我们的 PWA 可安装在您的设备上，它必须在安全环境中交付。通常，这意味着它必须通过 HTTPS 提供服务。
  - 要设置 PWA，您需要了解一些技术，如 Linux、Docker 和反向代理，如 `Nginx`、`Caddy` 或 `Traefik`。使用这些工具可以帮助简化构建和部署符合您需求的 PWA 的过程。虽然没有可用的“一键安装”选项，但可以安全地通过 HTTPS 部署您的 Open WebUI 实例需要用户经验，使用这些资源可以更轻松地创建和部署符合您需求的 PWA。

- ✒️🔢 **完全支持 Markdown 和 LaTeX**: 通过完善的 Markdown 和 LaTeX 功能提升您的 LLM 体验，实现丰富互动。

- 🧩 **模型构建器**: 直接从 Open WebUI 轻松创建 Ollama 模型。创建和添加自定义角色和代理，定制聊天元素，通过 [Open WebUI Community](https://openwebui.com/) 集成轻松导入模型。

- 📚 **本地和远程 RAG 集成**: 在聊天互动的未来中探索文件，使用我们先进的检索增强生成 (RAG) 技术在您的聊天中探索文件。文件可以加载到工作区，然后可以在查询前使用 `#` 符号访问，或通过以 `#` 开头的提示语加上 URL 来实现 Web 内容集成。

- 🔍 **RAG 的网页搜索**: 您可以使用各种搜索提供商进行网页搜索，并将结果直接注入到您的本地检索增强生成 (RAG) 体验中。

- 🌐 **网页浏览功能**: 使用 `#` 命令加上 URL，将网站无缝集成到您的聊天体验中。此功能使得能够将 Web 内容直接整合到对话中，从而增强互动的丰富性和深度。

- 🎨 **图像生成集成**: 无缝整合图像生成功能，用动态视觉内容丰富您的聊天体验。

- ⚙️ **并发模型使用**: 轻松同时与多个模型互动，利用它们的独特优势以获得最佳响应。并行利用多种模型模式以提升您的体验。

- 🔐 **基于角色的访问控制 (RBAC)**: 确保通过限制权限实现安全访问。只有授权人员可以访问您的 Ollama，模型创建和拉取权利仅限于管理员。

- 🌐🌍 **多语言支持**: 通过我们的国际化 (`i18n`) 支持体验您喜欢的语言的 Open WebUI。我们邀请您加入我们，扩大我们支持的语言！我们正在积极寻找贡献者！

- 🌟 **持续更新**: 我们致力于通过定期更新、修复和新功能来改进 Open WebUI。

## 以及许多其他显著功能，包括... ⚡️

---

### 🔧 管道支持

- 🔧 **管道框架**: 通过我们的模块化插件框架无缝集成和定制您的 Open WebUI 体验，以增强定制化和功能性 (https://github.com/open-webui/pipelines)。我们的框架允许轻松添加自定义逻辑和集成 Python 库，从 AI 代理到家居自动化 API。

- 📥 **上传管道**: 管道可以直接从 `管理面板` > `设置` > `管道` 菜单上传，简化了管道管理过程。
#### 我们的管道框架的可能性无穷无尽，几乎没有限制。从几个预构建的管道开始，帮助您入门！

- 🔗 **函数调用**: 通过管道无缝集成 [函数调用](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)，以利用高级函数调用功能增强您的 LLM 互动。

- 📚 **自定义 RAG**: 无缝集成 [自定义检索增强生成 (RAG)](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag) 管道，以通过自定义 RAG 逻辑增强您的 LLM 互动。

- 📊 **使用 Langfuse 进行消息监控**: 通过 [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py) 管道实时监控和分析消息互动使用统计。

- ⚖️ **用户速率限制**: 通过控制发送到 LLM 的请求流量来有效管理 API 使用，防止超过速率限制，使用 [速率限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py) 管道。

- 🌍 **实时 LibreTranslate 翻译**: 通过 [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py) 管道，在您的 LLM 互动中集成实时翻译，实现跨语言交流。
  - 请注意，此管道需要在 Docker 容器中进一步设置 LibreTranslate 才能工作。

- 🛡️ **有害消息过滤**: 我们的 [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py) 管道自动过滤有害消息，以保持清洁和安全的聊天环境。

- 🔒 **LLM-Guard**: 使用 [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py) 管道确保安全的 LLM 互动，具有检测和减轻针对大型语言模型的巧妙输入操控的提示注入扫描仪。这保护您的 LLM 免受数据泄漏，并增加了对提示注入攻击的抵抗力。

- 🕒 **对话轮次限制**: 通过 [对话轮次限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py) 管道设置对话轮次限制，以改善互动管理。

- 📈 **OpenAI 生成统计**: 我们的 [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py) 管道为 OpenAI 模型提供详细的生成统计。

- **🚀 多模型支持**: 我们与来自 [各种提供商](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers) 的各种 AI 模型的无缝集成，通过广泛的语言模型选择和互动拓展了您的可能性。

#### 除了广泛的功能和定制选项外，我们还提供 [一系列示例管道](https://github.com/open-webui/pipelines/tree/main/examples) 供您使用，以及 [一个实用的示例框架管道](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py) 帮助您入门。这些资源将简化您的开发过程，使您能够快速创建强大的 LLM 互动，使用管道和 Python。祝您编码愉快！💡

---

### 🖥️ 用户体验

- 🖥️ **直观界面**: 聊天界面以用户为中心进行设计，汲取了 ChatGPT 的用户界面灵感。

- ⚡ **快速响应**: 享受可靠的快速和响应性能。

- 🎨 **启动屏幕**: 简单的加载启动屏幕，提供更流畅的用户体验。

- 📦 **Pip 安装方法**: 可以通过命令 `pip install open-webui` 安装 Open WebUI，简化了过程，使新用户更容易上手。欲了解更多信息，请访问：https://pypi.org/project/open-webui/。

- 🌈 **主题自定义**: 个性化您的 Open WebUI 体验，提供多种选项，包括多种稳固但流线型的主题，可自定义聊天背景图像，以及三种模式选项：浅色、深色或 OLED 深色模式 - 或者让 *Her* 为您选择！;)

- 💻 **代码语法高亮**: 我们的语法高亮功能增强代码可读性，提供清晰简明的代码视图。

- ↕️ **双向聊天支持**: 可以轻松在左到右和右到左聊天方向之间切换，以适应各种语言偏好。

- 📱 **移动可访问性**: 可以通过简单的滑动手势在移动设备上打开和关闭侧边栏。

- 📂 **统一工作区**: 一个统一的工作区部分提供访问所有模型文件、提示、文档、工具和功能的便捷位置，简化您的工作流程。

- 💾 **持久设置**: 受益于 Open WebUI 中保存和持久的设置，存储在 config.json 文件中，便于访问和重复使用。

- ❓ **快速访问文档和快捷方式**: 主界面屏幕右下角的问号按钮（适用于较大屏幕，如台式机和笔记本电脑）提供用户轻松访问 Open WebUI 文档页面和可用键盘快捷键。

- 📜 **变更日志和检查更新**: 用户可以在 `设置` > `关于` > `查看新内容` 菜单中访问全面的变更日志和检查更新，提供最新功能、改进和错误修复的快速概览，以及检查更新的能力。

---

### 💬 对话

- 🔍 **RAG 嵌入支持**: 直接在 `管理面板` > `设置` > `文档` 菜单中更改检索增强生成 (RAG) 嵌入模型，改善文档处理。此功能支持 Ollama 和 OpenAI 模型。

- 📜 **RAG 功能中的引用**: 检索增强生成 (RAG) 功能允许用户轻松跟踪提供给 LLM 的文档上下文，并添加引用作为参考点。

- 🌟 **增强的 RAG 管道**: 我们的 RAG 嵌入功能的可切换混合搜索子功能，通过 `BM25` 增强 RAG 功能，使用 `CrossEncoder` 提供的重新排名，并可配置相关性分数阈值。

- 📹 **YouTube RAG 管道**: 专用的检索增强生成 (RAG) 管道，通过视频 URL 总结 YouTube 视频，直接与视频转录互动。

- 🔄 **多模态支持**: 轻松与支持多模态互动的模型互动，包括图像（例如，LLaVA）。

- 🤖 **多模型支持**: 快速在不同模型之间切换以进行多样的聊天互动。

- 👥 **'@' 模型集成**: 通过在对话中无缝切换到任何可访问的本地或外部模型，用户可以在一次聊天中利用多个模型的集体智慧。这可以通过在聊天中使用 `@` 命令指定模型名称来完成。

- 🏷️ **对话标记**: 轻松分类和定位标记的聊天，以便快速参考和简化数据收集。

- 👶 **聊天克隆**: 轻松克隆和保存任何聊天的快照，以供将来参考或继续。此功能使您可以轻松地从上次中断的地方继续或与他人共享您的会话。要创建聊天的副本，只需点击聊天下拉选项中的 `克隆` 按钮。您能跟上您的克隆吗？

- 📜 **提示预设支持**: 使用聊天输入中的 `/` 命令即时访问自定义预设提示。轻松加载预定义的对话启动器，加快您的互动。通过 [Open WebUI Community](https://openwebui.com/) 集成轻松导入提示或创建自己的提示！

- 📅 **提示变量支持**: 在系统提示中可以利用提示变量，如 `{{CLIPBOARD}}`、`{{CURRENT_DATE}}`、`{{CURRENT_DATETIME}}`、`{{CURRENT_TIME}}`、`{{CURRENT_TIMEZONE}}`、`{{CURRENT_WEEKDAY}}`、`{{USER_NAME}}`、`{{USER_LANGUAGE}}` 和 `{{USER_LOCATION}}`，或通过使用斜杠命令直接在聊天中选择提示。
  - 请注意，`{{USER_LOCATION}}` 提示变量需要通过 HTTPS 的安全连接。要使用此特定提示变量，请确保从 `设置` > `界面` 菜单中切换打开 `{{USER_LOCATION}}`。
  - 请注意，`{{CLIPBOARD}}` 提示变量需要访问您设备的剪贴板。

- 🧠 **记忆功能**: 通过 `设置` > `个性化` > `记忆` 菜单手动添加您希望 LLM 记住的信息。记忆可以添加、编辑和删除。

---

### 💻 模型管理


- 🛠️ **模型构建器**: 所有模型都可以使用模型工作区内的持久模型构建器模式进行构建和编辑。

- 📚 **模型的知识支持**: 能够将函数和文档直接附加到模型上，从模型工作区增强每个模型的信息。

- 🗂️ **模型预设**: 为 Ollama 和 OpenAI API 创建和管理模型预设。

- 🏷️ **模型标记**: 模型工作区允许用户使用标记组织他们的模型。

- 📋 **模型选择器下拉排序**: 可以通过在模型工作区中拖放模型到所需位置来轻松组织模型，然后反映在模型下拉菜单中。

- 🔍 **模型选择器下拉**: 通过包含的搜索筛选器和详细的模型信息（带有模型标签和模型描述）轻松查找和选择您的模型。

- ⚙️ **高级参数的精细控制**: 通过调整模型参数，如 `seed`、`temperature`、`frequency penalty`、`context length`、`seed` 等，获得更深层次的控制。

- 🔄 **无缝集成**: 从 [Ollama library](https://ollama.com/library/) 上的模型页面直接复制任何 `ollama run {model:tag}` CLI 命令，并将其粘贴到模型下拉菜单中，轻松选择和拉取模型。

- 🗂️ **创建 Ollama 模型文件**: 要为 Ollama 创建模型文件，请导航到 `管理面板` > `设置` > `模型` > `创建模型` 菜单。

- ⬆️ **GGUF 文件模型创建**: 通过从 `管理设置` > `设置` > `模型` > `实验性` 菜单直接从 Open WebUI 上传 GGUF 文件，轻松创建 Ollama 模型。该过程已简化，可以选择从您的机器上传或从 Hugging Face 下载 GGUF 文件。

- ⚙️ **默认模型设置**: 新聊天的默认模型首选项可以在移动设备的 `设置` > `界面` 菜单中设置，或者可以更轻松地在新聊天中通过桌面 PC 和笔记本电脑上的模型选择器下拉菜单设置。

- 💡 **LLM 响应见解**: 可以查看每个生成响应的详细信息，包括外部模型 API 见解和全面的本地模型信息。

- 📥🗑️ **下载/删除模型**: 可以轻松地从 Open WebUI 下载或删除模型。

- 🔄 **更新所有 Ollama 模型**: 一个方便的按钮允许用户在一次操作中更新所有本地安装的模型，简化了模型管理。

- 🍻 **TavernAI 角色卡集成**: 在我们的模型构建器中体验增强的视觉叙事。用户可以无缝地将 TavernAI 角色卡 PNG 直接集成到他们的模型文件中，创造更身临其境和吸引人的用户体验。

- 🎲 **模型游乐场 (Beta)**: 尝试模型游乐场区域（`beta`），允许用户在沙盒环境中轻松测试和探索模型能力和参数，然后再在实时聊天环境中部署。

---

### 👥 协作

- 🗨️ **本地聊天共享**: 生成并分享聊天链接，增强协作和沟通。

- 👍👎 **RLHF 注释**: 通过赞成或反对您的消息，并提供文本反馈来增强消息的影响，创建用于人类反馈强化学习 (`RLHF`) 的数据集。利用您的消息来训练或微调模型，同时确保本地保存的数据的机密性。

- 🤝 **社区共享**: 通过点击 `共享到 Open WebUI Community` 按钮与 [Open WebUI Community](https://openwebui.com/) 共享您的聊天会话。此功能允许您与其他用户互动并在平台上进行协作。
  - 要使用此功能，请登录到您的 Open WebUI Community 帐户。共享您的聊天可以促进一个充满活力的社区，鼓励知识共享，并促进联合问题解决。请注意，聊天会话的社区共享是一个可选功能。只有管理员可以在 `管理设置` > `设置` > `常规` 菜单中切换此功能的开启或关闭。

---

### 📚 历史与归档

- 📜 **聊天历史**: 通过聊天导航侧边栏轻松访问和管理您的对话历史。在 `设置` > `聊天` 菜单中切换关闭聊天历史，以防止在新互动中创建聊天历史。

- 🔄 **再生历史访问**: 轻松回顾和探索整个 LLM 响应再生历史。

- 📬 **归档聊天**: 轻松存储与模型进行的已完成对话，以便将来参考或互动，保持整洁和无杂乱的聊天界面。

- 🗃️ **全部归档聊天**: 此功能允许您一次性快速归档所有聊天。

- 📦 **将所有归档聊天导出为 JSON**: 此功能使用户能够轻松导出所有归档聊天到单个 JSON 文件中，可用于备份或传输目的。

- 📄 **下载聊天为 JSON/PDF/TXT**: 轻松以您偏好的 `.json`、`.pdf` 或 `.txt` 格式单独下载您的聊天。

- 📤📥 **导入/导出聊天历史**: 通过 `导入聊天` 和 `导出聊天` 选项无缝移动您的聊天数据。

- 🗑️ **删除所有聊天**: 此选项允许您永久删除所有聊天，确保清新的开始。

---

### 🎙️ 语音与可访问性

- 🗣️ **语音输入支持**: 通过语音互动与您的模型互动；享受直接对模型讲话的便利。此外，探索在静默 3 秒后自动发送语音输入的选项，以获得流畅的体验。
  - 需要手动设置安全连接（HTTPS）才能访问麦克风，或 [手动列入白名单，风险自担](https://docs.openwebui.com/troubleshooting/microphone-error)。

- 😊 **表情符号调用**: 从 `设置` > `界面` 菜单中切换开启此功能，允许 LLM 在语音通话中使用表情符号表达情感，以实现更动态的互动。
  - 需要通过 HTTPS 的安全连接才能访问麦克风。

- 🎙️ **免提语音通话功能**: 无需使用双手即可发起语音通话，使互动更加无缝。
  - 需要通过 HTTPS 的安全连接来访问麦克风。

- 📹 **视频通话功能**: 启用与支持视觉模型（如 LLaVA 和 GPT-4o）的视频通话，为您的通信增添视觉维度。
  - 需要通过 HTTPS 的安全连接来访问摄像头和麦克风。

- 👆 **轻触中断**: 在移动设备上轻触即可停止 AI 在语音对话中的讲话，确保对互动的无缝控制。

- 🔊 **可配置的文本到语音端点**: 使用可配置的兼容 OpenAI 的端点自定义您的文本到语音体验，以朗读 LLM 响应。

---

### 🐍 代码执行

- 🚀 **通用、与 UI 无关、兼容 OpenAI 的插件框架**: 无缝集成和定制 [Open WebUI 管道](https://github.com/open-webui/pipelines) 以高效处理数据和训练模型，确保最终的灵活性和可扩展性。

- 🛠️ **原生 Python 函数调用**: 直接在 Open WebUI 中访问 Python 的强大功能，通过原生函数调用。通过内置代码编辑器轻松集成自定义代码，构建独特功能，如自定义 RAG 管道、网页搜索工具，甚至通过内置代码编辑器的代理类操作，在 `工具` 和 `功能` 工作区中无缝开发和集成函数代码。

- 🐍 **Python 代码执行**: 通过 Pyodide 在浏览器中本地执行 Python 代码，支持 Pyodide 的一系列库。

- 🌊 **Mermaid 渲染**: 使用 [Mermaid 图表和绘图工具](https://mermaid.js.org/intro/) 直接在 Open WebUI 中创建视觉吸引力的图表和流程图，支持 Mermaid 语法渲染。

---

### 🔒 集成与安全

- ✨ **多种兼容 OpenAI 的 API 支持**: 无缝集成和定制各种兼容 OpenAI 的 API，增强您的聊天互动的多样性。

- 🔑 **简化的 API 密钥管理**: 轻松生成和管理秘密密钥，以利用 Open WebUI 与 OpenAI 库集成，简化集成和开发。

- 🌐 **HTTP/S 代理支持**: 使用 `http_proxy` 或 `https_proxy` 环境变量轻松配置网络设置。设置这些变量时，应包含 HTTP 和 HTTPS 代理的 URL。

- 🌐🔗 **外部 Ollama 服务器连接**: 通过配置环境变量无缝链接到托管在不同地址的外部 Ollama 服务器。

- 🛢️ **外部数据库支持**: 通过 `DATABASE_URL` 环境变量无缝连接到自定义 SQLite 或 Postgres 数据库。

- 🌐🗣️ **外部语音转文本支持**: 添加外部语音转文本 (`STT`) 服务提供了增强的灵活性，允许用户选择他们偏好的提供商以实现无缝互动。

- 🌐 **远程 ChromaDB 支持**: 通过连接到远程 ChromaDB 服务器扩展您的数据库功能。

- 🔀 **多个 Ollama 实例负载均衡**: 轻松分配聊天请求到多个 Ollama 实例，以提高性能和可靠性。

---

### 👑 管理

- 👑 **超级管理员指定**: 自动将第一个注册用户指定为超级管理员，角色不可更改，其他管理员也无法更改。

- 🛡️ **细粒度用户权限**: 通过可自定义的基于角色的权限限制用户操作和访问，确保只有授权人员才能执行特定任务。

- 👥 **多用户管理**: 分页的直观管理面板允许您无缝管理多个用户，简化用户管理和用户生命周期管理。

- 🔧 **管理面板**: 用户管理系统旨在简化用户的入职和管理，提供直接添加用户或通过 CSV 导入批量添加用户的选项。

- 👥 **活跃用户指示器**: 监控活跃用户的数量以及谁在使用哪些模型，帮助评估由于用户数量过多可能对性能产生的影响。

- 🔒 **默认注册角色**: 为新注册用户指定默认角色为 `待定`、`用户` 或 `管理员`，提供灵活性以管理新用户的权限和访问级别。

- 🔒 **防止新用户注册**: 启用选项以禁用新用户注册，限制访问平台并保持固定用户数量。

- 🔒 **防止聊天删除**: 管理员可以切换设置以防止所有用户删除他们的聊天消息，确保所有聊天消息保留以便审计或合规。

- 🔗 **Webhook 集成**: 通过 webhook 订阅新用户注册事件（兼容 `Discord`、`Google Chat`、`Slack` 和 `Microsoft Teams`），提供实时通知和自动化功能。

- 📣 **可配置的通知横幅**: 管理员可以在 config.json 中创建可自定义的横幅，具有内容、背景颜色（`信息`、`警告`、`错误`或`成功`）和可解除性选项。横幅仅对已登录用户可见，确保敏感信息的机密性。

- 🛡️ **模型白名单**: 通过允许管理员为 `用户` 角色的用户白名单模型，增强安全性和访问控制，确保只有授权模型可以访问。

- 🔑 **社区共享的管理员控制**: 管理员可以通过 `管理面板` > `设置` 菜单中的切换，为所有用户启用或禁用社区共享。此切换允许管理员管理可访问性和隐私，确保安全的环境。管理员可以为所有用户启用或禁用 `在社区中共享` 按钮，允许他们控制社区参与和协作。

- 📧 **可信电子邮件认证**: 可选使用可信电子邮件头进行认证，增加额外的安全层和认证，保护您的 Open WebUI 实例。

- 🔒 **后端反向代理支持**: 通过 Open WebUI 的后端与 Ollama 之间的直接通信增强安全性。此关键功能消除了在局域网 (LAN) 上公开 Ollama 的需求。来自 Open WebUI 的 `/ollama/api` 路由的请求无缝重定向到 Ollama，从后端增强整体系统安全性，并提供额外的保护层。

- 🔒 **认证**: 请注意，Open WebUI 本身不支持联合认证方案，如 SSO、OAuth、SAML 或 OIDC。然而，它可以配置为将认证委托给认证反向代理，有效实现单点登录 (`SSO`) 体验。此设置允许您集中用户认证和管理，提升安全性和用户便利性。通过将 Open WebUI 与认证反向代理集成，您可以利用现有认证系统并简化用户对 Open WebUI 的访问。有关配置此功能的更多信息，请参阅 [联合认证支持](https://docs.openwebui.com/features/sso)。

- 🔓 **可选认证**: 享受通过将 `WEBUI_AUTH` 设置为 `False` 禁用认证的灵活性。这是没有现有用户的新安装的理想解决方案，或者可用于演示目的。

---
